
* Kafka: Idempotência e garantias

Lide com múltiplos tópicos de envio no mesmo serviço
Extraia camadas de serviços
Paralelize pools de threads
Facilite a criação de novos serviços
Entenda como obter garantias relativas ao envio ou entrega das mensagens


--------------------------------------------------------------------------------

rm -rf ../data/*

./bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic ECOMMERCE_NEW_ORDER --partitions 3



1. Ligar o zookeeper
	$ cd /home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
	$ ./bin/zookeeper-server-start.sh ./config/zookeeper.properties

2. Ligar o kafka
	$ cd /home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
	$ ./bin/kafka-server-start.sh ./config/server1.properties
	$ ./bin/kafka-server-start.sh ./config/server2.properties
	$ ./bin/kafka-server-start.sh ./config/server3.properties
	$ ./bin/kafka-server-start.sh ./config/server4.properties
	$ ./bin/kafka-server-start.sh ./config/server5.properties


3. Listar os recursos
	* listar os topicos para ver o numero de particoes
	./bin/kafka-topics.sh --describe --bootstrap-server localhost:9092

	* ver todos os topicos por grupos 
	./bin/kafka-consumer-groups.sh --all-groups --bootstrap-server localhost:9092 --describe


--------------------------------------------------------------------------------

colocar em todos os modulos de servicos do InteliJ: Run -> Edit Configurations -> Workin directory:
$MODULE_WORKING_DIR$




**************************************************
-------------------------------------------------
01.2 - Organização e lidando com múltiplos tópicos de envio em um mesmo serviço

	Consumer
	br/com/alura/ecommerce/consumer/ConsumerFunction.java
	br/com/alura/ecommerce/consumer/GsonDeserializer.java
	br/com/alura/ecommerce/consumer/KafkaService.java

	Producer
	br/com/alura/ecommerce/dispatcher/GsonSerializer.java
	br/com/alura/ecommerce/dispatcher/KafkaDispatcher.java

-------------------------------------------------
1.3 - Micro serviços de email e fast delegate real



	Retirei o envio do email das funcoes: NewOrderServlet e NewOrderMain e criei um servico que fica ouvindo
	o  ECOMMERCE_NEW_ORDER e pega o email, prepara e envia.

	Agora o servico de newOrder esta preocupando so com sua responsabilidade de criar uma nova ordem.
	o problema ao enviar o e-mail esta para outra galera. fast-delegate.

	service-email-new-order
		br/com/alura/ecommerce/Email.java
		br/com/alura/ecommerce/EmailNewOrderService.java
		br/com/alura/ecommerce/Order.java


	service-http-ecommerce
		br/com/alura/ecommerce/NewOrderServlet.java

	service-new-order
		br/com/alura/ecommerce/NewOrderMain.java




**************************************************
-------------------------------------------------
02.1 Extraindo uma camada de serviços

	Rodar varias instancias de um serico direto pelo APP. sem ter que rodar o mesmo programa ao mesmo tempo.

	Procuro na documentacao: java class kafkaproducer
	https://kafka.apache.org/0100/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html
	* The producer is thread safe.

	Procuro na documentacao: java class kafkaconsumer
	https://kafka.apache.org/10/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html
	* The consumer is not thread-safe.


	service-email
		EmailService.java
		ConsumerService.java
		ServiceFactory.java
		ServiceProvider.java


-------------------------------------------------
02.2 Paralelizando com pools de threads

	Rodar 10 threads do servico consumir e-mail.

service-email
	EmailService.java

		new ServiceRunner(EmailService::new).start(5);

	ConsumerService.java
	ServiceFactory.java
	ServiceProvider.java
	ServiceRunner.java

Funcoes de loop para olhar depois
* IntStream.rangeClosed()
* Executors.newFixedThreadPool();

------------------------------------------------
02.3 Facilidade de criar novos serviços

	common-kafka
		ConsumerService.java
		ServiceFactory.java
		ServiceProvider.java
		ServiceRunner.java

	service-email
		EmailService.java

	service-reading-report
		ReadingReportService.java

------------------------------------------------
02.5 Facilidade de criar novos serviços

	* extraindo uma camada de interface de serviço
	* paralelizando com thread pools
	* simplicidade ao criar novos componentes



**************************************************
-------------------------------------------------
03.1 Offset latest e earliest

	* como lidar com latest e earliest (AUTO_OFFSET_RESET_CONFIG: latest e earliest)


	common-kafka
		KafkaService.java
	        * OFFSET de mensagens
	        	- A partir de onde devo comecar a receber, do inicio, da ultima?
	        properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");
	        	- nesse caso AUTO_OFFSET_RESET_CONFIG, caso nao tenha servidor, posso perder mensagens

        	Documentacao - ConsumerConfig:
        		
        		* https://kafka.apache.org/23/javadoc/org/apache/kafka/clients/consumer/ConsumerConfig.html
        		* https://kafka.apache.org/23/javadoc/constant-values.html#org.apache.kafka.clients.consumer.ConsumerConfig.AUTO_OFFSET_RESET_CONFIG
        		* o kafka por padrao nao armazena eterno.
        			AUTO_OFFSET_RESET_CONFIG -> esse cara resolve se quer pegar somente os mais atuais, ou os mais antigos.
        			- latest - pega o ultimo, mais recente;
        			- earliest - se ainda tem mensagens no kafka que nao foram apagadas eu pego todas (pega as do passado);

	service-email-new-order
		EmailNewOrderService.java



    /**
     * <code>auto.offset.reset</code>
     */
    public static final String AUTO_OFFSET_RESET_CONFIG = "auto.offset.reset";
    public static final String AUTO_OFFSET_RESET_DOC = "What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted): <ul><li>earliest: automatically reset the offset to the earliest offset<li>latest: automatically reset the offset to the latest offset</li><li>none: throw exception to the consumer if no previous offset is found for the consumer's group</li><li>anything else: throw exception to the consumer.</li></ul>";



./bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic ECOMMERCE_NEW_ORDER --partitions 3

3. Listar os recursos
	* listar os topicos para ver o numero de particoes
	./bin/kafka-topics.sh --describe --bootstrap-server localhost:9092

	* ver todos os topicos por grupos 
	./bin/kafka-consumer-groups.sh --all-groups --bootstrap-server localhost:9092 --describe


http://localhost:8080/new?email=carlosofpersia1@hotmail.com&amount=1







**************************************************
-------------------------------------------------
04.1 - O problema da mensagem duplicada





-------------------------------------------------
04.2 - Kafka transacional


















**************************************************
-------------------------------------------------
5.1 - Id natural e idempotência no banco

-------------------------------------------------
5.2 - Extraindo o common database

-------------------------------------------------
5.3 - Idempotência e fast delegate

-------------------------------------------------
5.4 - Idempotência em apis












--------------------------------------------

Apache Kafka
O Apache Kafka é uma plataforma de streaming distribuída. Através dele é possível processar uma grande quantidade de dados e entregá-los em tempo real aos seus consumidores.

Usado no LinkedIn, Netflix, Twitter e várias outras empresas o Kafka se tornou a ferramenta principal para criar pipeline de dados e enviar, processar e consumir mensagens de forma distribuída, algo muito comum em aplicações baseadas em Microsserviços.

Esta formação foi criada em parceria com o Nubank.


1. Streams, Cluster e Microsserviços
Mergulhe de cabeça no mundo de comunicação assíncrona! Entenda as vantagens do Kafka como broker de mensagens e aprenda como usar Producers, Processors e Consumers. Saiba como se conectar aos serviços externos e aumente a disponibilidade através de um cluster. Veja na pratica como paralelizar e escalar a execução construindo uma solução baseada na arquitetura de microsserviços!


2. Dead Letter Queue e Garantias de entrega
Agora que você já tem bom conhecimento sobre Kafka e a arquitetura de microserviços avance no uso dela. Replica os seus dados e saiba como lidar com erros no processamento. Aprenda como definir um dead letter queue e tentativas de reenvio. Crie múltiplos tópicos para o mesmo serviço e saiba como obter garantias sobre o envio e entrega de mensagens.


--------------------------------------------

* Definição de Pipeline da Dados
Um pipeline de dados é uma série de etapas de processamento de dados. Se os dados não estiverem carregados na plataforma de dados, eles serão ingeridos no início do pipeline. Depois, há uma série de etapas nas quais cada uma fornece uma saída que é a entrada para a próxima etapa. Isso continua até que o pipeline esteja completo. Em alguns casos, etapas independentes podem ser executadas em paralelo.

Os pipelines de dados consistem em três elementos principais: uma fonte, uma ou mais etapas de processamento e um destino. Em alguns pipelines de dados, o destino pode ser chamado de coletor. Os pipelines de dados permitem o fluxo de dados de um aplicativo para um Data Warehouse, de um Data Lake para um banco de dados analítico ou para um sistema de processamento de pagamentos, por exemplo. Os pipelines de dados também podem ter a mesma fonte e coletor, de modo que o pipeline seja apenas para modificar o conjunto de dados. Sempre que os dados são processados ​​entre o ponto A e o ponto B (ou pontos B, C e D), há um pipeline de dados entre esses pontos.

