


* Apache Kafka

O Apache Kafka é uma plataforma de streaming distribuída. Através dele é possível processar uma grande quantidade de dados e entregá-los em tempo real aos seus consumidores.
Usado no LinkedIn, Netflix, Twitter e várias outras empresas o Kafka se tornou a ferramenta principal para criar pipeline de dados e enviar, processar e consumir mensagens de forma distribuída, algo muito comum em aplicações baseadas em Microsserviços.
Esta formação foi criada em parceria com o Nubank.

1. Streams, Cluster e Microsserviços
Mergulhe de cabeça no mundo de comunicação assíncrona! Entenda as vantagens do Kafka como broker de mensagens e aprenda como usar Producers, Processors e Consumers. Saiba como se conectar aos serviços externos e aumente a disponibilidade através de um cluster. Veja na pratica como paralelizar e escalar a execução construindo uma solução baseada na arquitetura de microsserviços!

* zookeeper (responsavel pelo broker);
* KAFKA - broker de mensagens (Producers, Processors e Consumers) - responsavel pelos processamentos;

https://www.infoq.com/br/articles/apache-kafka-best-practices-to-optimize-your-deployment/
* broker - permite que aplicações, sistemas e serviços comuniquem entre si e troquem informações;
* MOM (Message Oriented Middleware).
O MOM (ou Broker - Intermediador) é um lugar onde os dados ficam salvos temporariamente, até o outro sistema conseguir processá-los. O MOM garante a entrega em algum momento e ajuda assim a lidar com indisponibilidade de sistemas e picos de processamento.
* lookup -> significa: pega pra mim!

/*****************************************************************/
-------------------------------------------------------------------
Aula.01 Introducao -> Mensageria/Streams:

Utilize Kafka para comunicação assíncrona
Aprenda a criar microsserviços com Kafka
Entenda as vantagens de Kafka para paralelismo e execução serializada
Entenda como funciona a serialização e deserialização no Kafka
Extraia uma camada de abstração própria com boas práticas

01.2 Instalando o Kafka localmente
http://www.basef.com.br/index.php/Atalhos_do_IntelliJ_Idea

// site do zookeeper
https://zookeeper.apache.org/releases.html#download
// site do kafka
https://kafka.apache.org/downloads
https://kafka.apache.org/quickstart
//plugins pom do maven para kakfa:
https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients/2.6.0
//plugins pom do maven para log:
https://mvnrepository.com/artifact/org.slf4j/slf4j-simple/1.7.30
//problema ao executar network do kafka
https://cursos.alura.com.br/forum/topico-uncaught-exception-in-thread-kafka-producer-network-thread-producer-1-124051

--------------------------------------------------------------------------------

1. Ligar o zookeeper
carloss@carloss-note:~/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ ./bin/zookeeper-server-start.sh ./config/zookeeper.properties

2. Ligar o kafka
carloss@carloss-note:~/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ ./bin/kafka-server-start.sh ./config/server.properties

3. criar um topico
    carloss@carloss-note:~/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
    $ ./bin/kafka-topics.sh --create --topic LOJA_NOVO_PEDIDO --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1

3.1 aumentar o numero de particoes
    $ ./bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic ECOMMERCE_NEW_ORDER --partitions 3

4. Listar os topicos existentes
carloss@carloss-note:~/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092
$ ./bin/kafka-topics.sh --describe --bootstrap-server localhost:9092
$ ./bin/kafka-consumer-groups.sh --all-groups --describe --bootstrap-server localhost:9092

5. Produzir mensagens
carloss@carloss-note:~/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic LOJA_NOVO_PEDIDO
$ ./bin/kafka-topics.sh --describe --topic LOJA_NOVO_PEDIDO --bootstrap-server localhost:9092
> pedido_0, 550
> pedido_1, 330
> pedido_2, 100

6. Consumir as mensagens
carloss@carloss-note:~/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ ./bin/kafka-console-consumer.sh --topic LOJA_NOVO_PEDIDO --bootstrap-server localhost:9092 --from-beginning

----------------------------------------------------

7. Criando projeto JAVA + MAVEN -> faco as configuracoes no InteliJ ...

    7.1 Criar um produtor de mensagem -> NewOrderMain
        criar o produtor de mensagem na classe - NewOrderMain - para produzir uma nova mensagem ao kafka.
        executo o passo 4. se der algum erro, rodar novamente, pois o topic ainda nao existe.
        $ ./bin/kafka-topics.sh --list --bootstrap-server localhost:9092
        $ ./bin/kafka-topics.sh --describe --bootstrap-server localhost:9092
        executo o passo 6. com o nome do meu topico - ECOMMERCE_NEW_ORDER - que foi definido na classe - NewOrderMain - para consumir a mensagem enviada.
        $ ./bin/kafka-console-consumer.sh --topic ECOMMERCE_NEW_ORDER --bootstrap-server localhost:9092 --from-beginning

    7.2 Criar um consumidor de mensagem -> FraudDetectorService
        criar o consumidor de mensagem na classe - FraudDetectorService - para receber as mensagens do kafka.
        rodar o 7.2 e depois o 7.1 para produzir e consumir.


----------------------------------------------------
* Produtores x Consumidores
Em um sistema bancário, um usuário inicia o processo de uma transação bancária, qual abordagem é baseada em produtores e consumidores de mensagens?
R. A requisição é feita por um site ou app cujo servidor envia uma mensagem de pedido de transação bancária.
Essa abordagem mistura o processo síncrono e a mensagem.

----------------------------------------------------
* O que aprendemos nessa aula:
O que são produtores
O que são consumidores
Criação de tópicos manualmente
Como instalar e rodar o Kafka.




/*****************************************************************/
-------------------------------------------------------------------
Aula.02.02 - Vários consumidores e produtores - Aula 02 -
- paralelizando tarefas em um servico

    * Refatorar nosso produtor "NerOrderMain.java" para enviar
        mensagens para os topicos ECOMMERCE_NEW_ORDER e ECOMMERCE_SEND_EMAIL.

    * Criar o Consumidor:
        EmailService.java -> Consumidor de e-mail
        consumer.subscribe(Collections.singletonList("ECOMMERCE_SEND_EMAIL"));

        LogService.java -> Consumidor de varios consumidores a partir de
        consumer.subscribe(Pattern.compile("ECOMMERCE.*"));

Aula.02.3 - Paralelizando e a importância das keys

    * Nao adinta ter mais de um consumidor para o mesmo topico para uma particao, deve aumentar as particoes.
        vi config/server.properties
        num.partitions=1

    * Aumentar o numero de particoes para paralelizar mais consumidores.
        ./bin/kafka-topics.sh --alter --zookeeper localhost:2181 --topic ECOMMERCE_NEW_ORDER --partitions 3

    * Da para duplicar os consumidores atraves do InteliJ.
    Na aba escrito o nome da classe ao lado direito de um martelo,
    escolher a classe "FraudDetectorService.java" deve-se colocar:
    "Edit configurations..." + "copy configuration " + "allow parallel run".
    * Tambem vamos colocar assinatura em key - "key, values" -  da forma correta para o processo de paralelizacao funcionar.
    Em NewOrderMain.java add uma key para toda vez que rodar pode randomicamente escolher um processo paralelo:
    * Key e a assinatura das partitions.
    /*
            var key = UUID.randomUUID().toString();
            var value = key + ",456,789.00";
            var record = new ProducerRecord<>("ECOMMERCE_NEW_ORDER", key, value);
            producer.send(record, callback).get();
    */

    * Verificar como estao distribuidos os registros pelos paralelamento
        ./bin/kafka-consumer-groups.sh --all-groups --describe --bootstrap-server localhost:9092

Aula02.4 - Max poll e dando mais chances para auto commit

//Em FraudDetectorService.java adicionar a configuracao MAX_POLL_RECORDS_CONFIG
maximo de registros para commitar. menos chance de perder registros para rebalanceamento
em tempo de execucao * Cuidado com POLL longo *.
* var records = consumer.poll(Duration.ofMillis(100)); *
properties.setProperty(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "1");


Aula02.6 - Exercicio Paralelização

* Qual a importância das chaves na paralelização de tarefas?
    - Ela é peça fundamental para paralelizar o processamento de mensagens
    em um tópico dentro do mesmo consumer group.
    - A chave é usada para distribuir a mensagem entre as partições existentes e
    consequentemente entre as instâncias de um serviço dentro de um consumer group.


Aula02.7 - O que aprendemos nessa aula:

Como rodar diversos consumidores no mesmo grupo
Como paralelizar tarefas
A importância da chave para hash
Cuidado com poll longo



/*****************************************************************/
-------------------------------------------------------------------
Aula.03.2 - Extraindo uma camada de consumidor (Refatorando o codigo)

Refatoracao das classes EmailService.java e FraudDetectorService.java
Criacao da Classe KafkaService.java
Criacao da Interface ConsumerFunction.java

---------------------------------------------
Aula.03.3 - Extraindo nossa camada de producer

Refatoracao das classe NewOrderMain.java
Criacao da classe KafkaDispatcher.java (para generizar a programacao do producer)

---------------------------------------------
Aula.03.5 - Our own layer

Qual a vantagem de criar nossa própria camada?
    Adotar boas práticas como evitar código duplicado.
    Definir padrões, boas práticas e evitar más práticas, permitindo novos/as devs começar a desenvolver rapidamente código pronto para produção.

---------------------------------------------
Aula.03.6 - O que aprendemos nessa aula:

A importância de evitar copy e paste
Criando nossa camada de abstração
Criando nosso Dispatcher (Producer)
Criando nosso Service (Consumer)




/*****************************************************************/
-------------------------------------------------------------------
Aula.04. Serialização customizada

-------------------------------------------------------------------
Aula.04.02 Diretórios do Kafka e Zookeeper
Tirar as filas do diretorio temporario do linux,
pois de tempos em tempos este e excluido.

$ ls /tmp/zookeeper/
$ ls /tmp/kafka-logs/

1. criar os diretorios em algum lugar bem pensado.
$ pwd
/home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ cd ..
$ mkdir data
$ mkdir data/zookeeper
$ mkdir data/kafka
$ cd data/
$ pwd
    // Esse e o caminho a ser trocado.
    /home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/data/(kafka|zookeeper)

2. Acessar as configuracoes do kafka para adicionar o path:

$ cd /home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ vi config/server.properties

############################# Log Basics #############################
# A comma separated list of directories under which to store log files
log.dirs=/tmp/kafka-logs
* Trocar por:
log.dirs=/home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/data/kafka


#listeners=PLAINTEXT://:9092
//posso alterar a porta se preciso for, isso e bom quando formos replicar a quantidade de brokers.
listeners=PLAINTEXT://:9093...


3. Acessar as configuracoes do zookeeper para adicionar o path:

$ cd /home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0
$ sudo vi config/zookeeper.properties
# the directory where the snapshot is stored.
dataDir=/tmp/zookeeper
* Trocar por:
dataDir=/home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/data/zookeeper


4. Testar nos novos lugares:
$ cd /home/carloss/Documents/Desenvolvimento/eclipse-workspace/JmsKafka/kafka_2.13-2.6.0

* ligar o  zookeeper
    $ ./bin/zookeeper-server-start.sh ./config/zookeeper.properties
* ligar o  kafka
    $ ./bin/kafka-server-start.sh ./config/server.properties



-------------------------------------------------------------------
Aula04.03 - Serialização com GSON

1. Usar generics no KafkaDispatcher.java
    class KafkaDispatcher<T>
    private final KafkaProducer<String, T> producer;
    public void send(String topic, String key, T value) ...

2. Usar o generics no recebimento do objeto requerido:
    try (var dispatcher = new KafkaDispatcher<Order>() ) {...
    try (var dispatcher = new KafkaDispatcher<String>() ) {...

3. Criar uma classe Order.java

4. Alterar a classe NewOrederMain.java para usar o KafkaDispatcher<T>
com o generics e fazer os tests com Order e String.

5. Transformar o Order para StringSerializer
Add a lib gson no pom e rodar o maven:
https://mvnrepository.com/artifact/com.google.code.gson/gson/2.8.6

6. Criar uma classe GsonSerializer.java e configura-la com o kafka para colocar em properties em KafkaDispatcher.java
properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, GsonSerializer.class.getName());

7. Rodar tudo e estamos felizes e contentes ate aqui!.


-------------------------------------------------------------------
Aula04.04 - Migrando o log
* Ajustando a classe LogService.java para usar o KafkaService.
* Criando 2 contructs para usar expressao regular no topic ... ECOMMERCE.*


-------------------------------------------------------------------
Aula04.05 - Deserialização customizada.
* Para usarmos ORDER e String no consumer.

* Criar a classe GsonDeserializer.java
* Criar a classe Email.java
* Alterar a NewOrderMain para usar a classe Email, pq agora todos sao objetos.
* Alterar a LogService.java (retorna deserialize String)
* Alterar a FraudDetectorService.java (retorna deserialize Order)
* Alterar a EmailService.java (retorna deserialize Email)


-------------------------------------------------------------------
Aula04.06 - Deserialização customizada.
* Para usarmos uma propriedade generica.
altero o contrutor do KafkaService.JAVA
    // add o parametro  em getProperties
        Map<String, String> overrideProperties;
    // Problema com deserializacao de String para Gson na hora de deserializar.
        properties.putAll(overrideProperties);

        try (var service = new KafkaService(
                LogService.class.getSimpleName(), Pattern.compile("ECOMMERCE.*")
                , logService::parse, String.class
                , Map.of(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()))) {
            service.run();
        }

        try (var service = new KafkaService<Order>(FraudDetectorService.class.getSimpleName()
                , "ECOMMERCE_NEW_ORDER", fraudDetectorService::parse, Order.class
                , new HashMap<>())) {
            service.run();
        };

        try ( var service = new KafkaService<Email>(EmailService.class.getSimpleName()
                , "ECOMMERCE_SEND_EMAIL", emailService::parse, Email.class
                , new HashMap<>())) {
            service.run();
        };

-------------------------------------------------------------------
Aula04.08 - O que aprendemos?

Como limpar os diretórios de log e dados do zookeeper e kafka
Como utilizar diretórios não temporátios para o zookeeper e kafka
Como utilizar o GSON
Criando um serializador customizado do Kafka
Verificar o conteúdo exato de uma mensagem em um programa
Deserialização customizada
Lidando com customização por serviço






/*****************************************************************/
-------------------------------------------------------------------
Aula.05. Microsserviços como módulos em um mono repo

-------------------------------------------------------------------

new -> module -> maven -> configuracoes:
    * Criar um novo modulo service-email
        e mover ServiceEmail.java -> refactor move ...
    * Criar um novo modulo service-frauddetector
        e mover FraudDetectorService.java
    * Criar um novo modulo service-log
        e mover LogService.java

Em todas os poms que foram criados clicar
-> "Alt + Insert" -> Escolhe Dependency
digitar "add dependency"
e escolher a pai.

-------------------------------------------------------------------
Aula.05.03 - Binários dos microsserviços

* colocar o Order.java e o Email.java com seus recursos e testar tudo.

--//--

Por fim rodar o maven GO para gerar um pacote de todo o projeto "ecommerce".
Em Maven Maven GO -> mvn package
E e gerado o projeto completo:
/home/carloss/Documents/Desenvolvimento/eclipse-workspace/estudos-java/CursoJMS_KAFKA/service-new-order/target/service-new-order-1.0-SNAPSHOT.jar


-------------------------------------------------------------------
Aula.05.05 - Bibliotecas comuns

Qual uma vantagem de extrair bibliotecas comuns?
    Múltiplos projetos se beneficiam da mesma base de código.
    Isso permite que devs foquem nos requerimentos únicos de seu projeto.


Aula.05.06 - O que aprendemos?

como criar módulos
como manter tudo em um mono repo
como gerenciar dependências entre módulos
como gerar os binários de cada módulo



Fim deste curso. Thanks












/*****************************************************************/

Curiosidade:
Aula.01 - Uma explicacao legal
01.1 Mensageria e Kafka

[00:00] Imagina um sistema de e-commerce, se é um sistema de e-commerce, o que que eu vou ter nele? Eu vou ter, por exemplo, o meu usuário acessando o meu sistema online. Então aqui dentro do meu usuário, eu tenho aqui o meu usuário, que é o meu cliente, o meu navegador, que eu vou chamar de usuário.
[00:17] Então no navegador, esse meu cliente está acessando o quê? A web e através da web, acessa um servidor Http. Então o acesso a esse servidor Http é feito, ele é feito e funciona. Vou colocar aqui uma setinha, bonitinha ao lado direito e funciona.
[00:42] Agora, o que mais que acontece? Vou diminuir aqui essa minha barra. Então, repara que o servidor Http tem diversas tarefas para fazer, por quê? Porque é um processo de compra, você está efetuando uma compra. Então, o que que eu tenho que fazer?
[00:55] Eu tenho que verificar se é uma fraude, eu tenho que antes de verificar se é uma fraude, enviar um e-mail dizendo: “Olha, a sua compra está sendo processada”, aí verifico se é fraude. Aí, se for fraude, eu fico [XXIninteligívelXX] e te notifico, sistemas de segurança.
[01:12] Alguma coisa de segurança, se não for fraude, o que que eu tenho que fazer? Eu tenho que de alguma maneira efetuar a compra, o pagamento de verdade. Se o pagamento for um sucesso, eu tenho que liberar o produto, por exemplo, se é um produto online, como um e-book.
[01:27] Então eu tenho que gerar o e-book com a versão customizada para aquele usuário ou usuária, que tem um nome daquela pessoa, o CPF, etc., e aí, sim, enviar esse produto por e-mail. Então, repara que vai ficando cada vez um passo depois do outro, um passo depois do outro, cada vez mais complexo.
[01:41] Uma coisa cada vez maior, cada vez maior. Vou separar isso aqui em setinhas, em setinhas mesmo, em quadradinhos e setinhas, para a gente ir vendo a coisa. Então o servidor, ele envia um e-mail. Aí, você fala: “Guilherme, ele poderia fazer a fraude?”.
[01:56] Depois do e-mail, um e-mail do tipo, recebi o seu pedido, então estou processando por fraude. Então, poderia ser, depois, é verdade? Eu poderia fazer isso aqui, nessa ordem e colocar todo esse código dentro de um único sistema, funcionária. Quer dizer, primeiro o meu servidor http, eu tenho um servidor http, o que que ele vai fazer?
[02:18] Lá dentro, ele envia um e-mail. O e-mail foi enviado? Verifica se é fraude. É fraude? Faz tal coisa e por aí, vai. Tudo dentro de um grande programa, uma linha depois da outra, um problema disso, muito direto para os sistemas é que, por exemplo, esperar o e-mail, quer dizer que tem que esperar um sistema externo me responder, o meu servidor SMTP, que envia e-mails.
[02:43] E pode ser que esse servidor esteja fora do ar, pode ser que esse servidor esteja lerdo, pode ser que não sei o quê. Então quer dizer, eu vou demorar para começar o processo de fraude, porque eu estou esperando o e-mail. Então é muito comum que em sistemas web, a gente queira dar uma resposta para o nosso usuário, o mais rápido possível.
[03:01] Isso é muito comum. Então é muito comum que esse tipo de tarefa, a gente faça e paralelo, a gente não faça isso sequencial. A gente costuma fazer isso em paralelos. Então, ele dispara o e-mail dispara o sistema de verificar se é fraude ao mesmo tempo. O que que quer dizer, dispara o e-mail, dispara o sistema, ele vai verifica se é fraude?
[03:23] Quer dizer que pode ser no mesmo computador duas trets, quer dizer que pode ser eu me comunicando com dois computadores diferentes e falando: “Olha, o computador aí que tem outro programa, envia um e-mail, uma requisição http, via rest”, seja o lá o que for.
[03:38] Aqui também, uma requisição http via rest ou uma outra trede, falando: “Detecta aí a fraude” e enquanto isso, eu já dei uma resposta aqui para o meu cliente dizendo: “Sua compra está sendo processada” e agora eu vou processando tudo isso em paralelo, na mesma máquinas, em máquinas distintas, são opções.
[03:58] Essa comunicação feita http, via rest, via outro tipo de mensageria, etc., são várias opções, o tradicional seria, primeiro na mesma máquina com várias tredes, depois em máquinas distintas se comunicando via http, que é uma maneira comum de ser feito isso, entre sistemas.
[04:16] E a gente vai... vamos para frente nesse sisteminha aqui, naqueles comentários que eu fiz, né? Então, eu detecto é fraude. Se é fraude ou não, eu vou ter que fazer alguma coisa, por exemplo, se for fraude... se não for fraude, eu tenho que fazer o quê?
[04:19] Efetuar o pagamento, quer dizer, aí sim, eu vou lá e cobro do cartão de credito da pessoa, assumindo que é cartão de crédito. Depois que eu cobrei do cartão de crédito, o que que eu tenho que fazer? Se for sucesso, eu tenho que preparar o envio, vamos pensar num bem digital, como um PDF, um E-book.
[04:48] Então, nesse caso, teria que gerar o PDF e por fim, eu teria que enviar o e-mail do PDF, então tudo isso teria que acontecer. Aqui, parece ter que ser sequencial, né? Porque eu não vou gerar o PDF, antes de gerar o pagamento ou pelo menos enviar o e-mail, eu não vou, antes de confirmar o pagamento, provavelmente.
[05:10] Então, você vai definir a ordem, o que que você quer fazer em paralelo ou não, mas você começa a ter agora mais várias setinhas, eu tenho aqui uma setinha da fraude, desse sistema de fraude ou desse código de fraude, para essa próxima parte.
[05:22] Aí, eu tenho do sistema de efetuar pagamento ou do código de efetuar pagamento, para gerar o PDF e por aí, vai. Eu estou tento até dificuldade de tanta setinha que eu tenho aqui, eu vou tendo dificuldade de arrastar esses caras, porque é muita coisa que tem que ser feita sequencialmente ou um código que chama http e o outro código.
[05:43] E para pra pensar, isso é no caro de sucesso, no caso de sucesso, efetuei o pagamento e no caso de fracasso? “Ah, no caso de fracasse, por exemplo, do pagamento, eu gostaria de também enviar um e-mail, eu também vou ter que enviar um e-mail de fracasso, nesse caso”.
[06:00] Então, nesse caso aqui, eu tenho que enviar um e-mail também, eu vou ter que ter um outro cara aqui, que é enviar o e-mail, que na verdade, não é e-mail do PDF, “Enviar o e-mail do fracasso”. Além disso tudo, eu gostaria, que eu tivesse suporte à produtos físicos.
[06:19] Então, quer dizer, se é produto físico, eu tenho um estoque e na hora que você pediu a compra, eu já tenho que reservar esse estoque para você. Então, eu tenho que aqui, logo de cara, já reservar o estoque, tem que reservar o estoque, então eu vou e reservo o estoque.
[06:36] Então eu tenho três... se são máquinas diferentes, com serviços diferentes, três requisições https, uma requisição http, outra requisição, outra, outra e por aí, vai. Ah, e calma aí, a compra foi confirmada? Efetuou o pagamento e a compra foi confirmada? E se ela for digital, o que que eu tenho que fazer?
[06:54] Eu tenho que confirmar do estoque, eu reservei? Agora eu tenho que confirmar o estoque, confirmar que vai embora, confirmar o estoque e se deu fracasso, o que que eu tenho que fazer? Possivelmente, vai depender de como você quer fazer, a o ordem, cancelar do estoque, só se for um produto físico.
[07:19] Então, se for esse caso, você vai ter que cancelar do estoque, se for físico. Calma aí, está ficando cada vez mais complexo e isso tudo aqui, eu posso ir falar: “Ah, eu tenho um serviço de estoque, que tem essas três URIs”, “Eu tenho o serviço de fraude, que em essa URI”, “O serviço de pagamento que tem essa URI”, “Eu tenho o serviço de PDF, que é essa URI”, “eu tenho o serviço de e-mail, que são essas três URIs”.
[07:41] Mas todas essas comunicações, todas essas setas, sou eu Guilherme quem programo, sou em quem faço todas elas. Eu sei quem está na outra ponta e envio uma mensagem http ou a gente pode definir outro termo, de acordo como essa requisição é feita, notificando o que eu gostaria que fosse feito ou algo do gênero.
[08:04] Vamos complicar mais ainda, como no mundo real. Tudo isso daqui, eu preciso de log, então eu preciso de toda a vez que eu disparo um e-mail, logar em algum lugar, que foi disparado um e-mail. Então, eu preciso de um sistema de log ou de algo de log, que eu tenha o quê?
[08:20] Tudo o que acontece agora vamos lá, “Boa sorte Guilherme”, sofre aqui é quem desenha, quem tem que ficar desenhando na mão as coisas. Todo mundo aqui tem que fazer o quê? Acessar o sistema de log, porque tudo o que acontece, tem que ir para o sistema de log.
[08:37] Tudo o que acontece, tem que ir para o sistema de log, por quê? Se eu quiser fazer uma auditoria, saber a ordem que aconteceram as coisas, qualquer coisa do gênero, tem que ir para o sistema de log. Então, reparem, eu nem vou terminar tudo do sistema de log e já está uma bagunça do tamanho de outro planeta, por quê?
[08:54] Porque vários sistemas, conhecem vários sistemas. Vários sistemas sabem como outro sistema funciona e você começa a ficar com esse emaranhado de todo mundo se conhecer e todo mundo saber como o outro funciona e todo mundo saber qual é o próximo passo e qual é o passo anterior, de onde que veio, para onde que vai e não sei o quê, todo mundo com tudo.
[08:13] Mais ainda, além do log, tem outras preocupações, outros concerns, que cortam a nossa aplicação inteira, que são Cross Cutting Concerns, o que que tem isso, por exemplo? Os dados... o Analytics, eu quero saber, como que a gente está de fraude, hoje a gente está com 10%? 10% é a nossa média histórica.
[09:32] Se hoje está 20%, opa, algo está acontecendo de errado com o nosso sistema de fraude ou com os fraudadores ou a gente está com o sistema de fraude... deu uma zoada hoje e aí, está detectando 20% de fraude, quando o normal 10, tem anos que o normal é 10%, estou citando exemplos.
[09:50] Então aconteceu alguma coisa hoje de estranha com o meu sistema ou realmente os fraudadores estão fazendo um ataque, alguma coisa, para tentar fraudar o meu sistema. Então, ei preciso de um Analytics, para acompanhar as métricas, para saber, tem alguma coisa fora do ar?
[10:04] Tem alguma coisa que não está dando conta? Tem alguma coisa que está dando mais erro do que o comum? Então, calma aí, se esse tipo de coisa, eu preciso saber, não só para fraude, eu preciso saber também para o pagamento. A taxa de pagamento está como a taxa histórica de sucesso ou a taxa de sucesso não está bem assim?
[10:21] A taxa de e-mails que são enviados com sucesso, que não são bounce, que não bate e volta, está na minha taxa normal ou está batendo e voltando mais? Então, quer dizer que os servidores de e-mail estão achando que eu sou spam e eu tenho que fazer alguma coisa? Analytics.
[10:34] “Ah, os PDFs, que eu estou gerando, eu estou gerando num ritmo que eu esperava ou não, estou gerando muito mais?” Então, deu algum bug ali e entrou num looping e infinito ou não, estou gerando a menos. Então ou é vendas a menos ou o sistema está lerdo e está acumulando de PDFs serem gerados.
[10:50] Analytics, tudo coisas Analytics. Então, repara, olha o fuzuê desse sistema, por que que a gente tem esse fuzuê? Porque todo mundo conhece todo mundo, não é todo mundo, mas auê, conhece o fuzuê, fica esse fuzuê total e aí, você tem que conhecer com quem você vai chamar requisição e é síncrono, só que é externo, mas se esse cara caiu, como que eu tenho que reagir com esse?
[11:15] Imagina, o Analytics caiu e aí, a fraude, o que que ela faz? Ela vai para a próxima fase ou ela espera o Analytics? O que que ela faz? Como é que eu faço para, tipo: “Não, não, vai para a próxima fase e daqui a pouco, quando o Analytics subir, eu aviso o Analytics. Boa sorte, implementar isso, boa sorte, por quê?
[11:31] Porque se o seu sistema de fraude cai agora, onde é que você anatou que tinha notificar o Analytics daqui um tempo? Aí é claro, você tem sistemas (poling), tem sistemas (wacher), tem sistema de (observes),.
[11:43] você começa a criar várias estruturas complexas, para tentar lidar com essa complexidade dos processos, do processo externo que a gente tem aqui dentro, que deixou de ser sequencial, passou a ser paralelo, por quê? Porque com isso a gente potencializa o desempenho da nossa aplicação.
[11:59] Então, eu posso executar 10 máquinas de fraude e uma só de e-mail, mas se de repente, efetuar o pagamento também, é uma coisa que precisa de muita máquina, tenho cinco máquinas, então eu posso escalar cada um desses serviços com máquinas distintas.
[12:12] Então, eu tenho essa vantagem de estar com tudo isso distribuído e paralelizado. Então, repara a bagunça que é trabalhar com esse tipo de sistema dessa forma é claro, existem sistemas e formas de trabalhar mais inteligentes ou pelo menos diferentes, que vão trazer certas vantagens nessas abordagens.
[12:32] Vamos dar uma pensadinha, como a gente pode fazer isso? Eu vou copiar tudo isso, vou colar aqui em baixo, colei aqui em baixo e o que eu quero fazer agora é repensar, represar todas essas setas. Vamos repensar todas essas setas aqui. Tudo isso aqui, eu quero repensar, por quê?
[12:55] Porque a ideia é que, eu não quero fazer com que eles se conheçam, eles não precisam se conhecer, por exemplo, claro, quando o meu cliente, que eu não copiei aqui, que é o meu usuário, o navegador, podia ser um aplicativo, podia ser outra coisa, que é o usuário final.
[13:12] Acessa o servidor http? Claro, conhece, está fazendo uma requisição, poderia ser um aplicativo fazendo uma requisição http, o que fosse. A partir daqui, o servidor http recebeu novo pedido de compra? Ele faz o quê? Ele simplesmente envia uma mensagem que se chama: novo pedido de compra.
[13:34] Então, eu tenho alguém aqui que simplesmente se chama... o meu broker, que é quem recebe mensagens. Então, eu simplesmente mando uma mensagem para o meu broker. Eu falo: “Broker, olha, toma aí, uma mensagem para você”.
[14:00] E aí, quando eu mando a mensagem para o broker, eu falo: “Olha, a minha mensagem é de nova compra”, ou “Novo pedido de compra”, eu poderia definir uma outra coisa. Eu mando essa mensagem e eu não sei quem vai receber isso, eu não sei e não importa quem vai receber isso, por quê?
[14:22] Porque o e-mail, que é disparado, quando tem um novo pedido de compra, ele está escutando esse tópico, ele está escurando esse assunto dessa mensagem. Então, ele está escutando qual assunto, mesmo? O assunto da nova compra, ele está escutando, mas não só ele, o fraude também está escutando isso.
[14:52] O fraude também, então o fraude também está escutando isso, mas não só isso, o reservar o estoque, também está escutando esse tópico e não só isso, o Analytics também está escutando esse tópico e o log também está escutando esse tópico, todos esses estão escutando esse tópico.
[15:08] O servidor http sabe alguma coisa sobre isso? Não, ele simplesmente envia uma mensagem falando: “Tenho um novo pedido de compra, aqui estão as informações”, todos esses sistemas estão escutando esse tópico, cada um fazer a sua tarefa de forma síncrona, na mesma máquina ou máquinas distribuídas, não estou nem aí.
[15:27] Então, para simplificar, eu nem preciso das setas, eu só preciso dizer que esse serviço que está rodando numa máquina escuta o “Nova compra”, vou colocar assim: “Nova compra”. O fraude está escutando o “Nova compra”, o reservar o estoque está escutando o “Nova compra”.
[15:49] O Analytics está escutando o “Nova compra” e o log está escutando o “Nova compra”, o que que acontece? Quando o e-mail é enviado, o que que acontece? O sistema de e-mails, o serviço de e-mail envia uma mensagem para o broker, falando o quê?
[16:05] Eu vou deixar aquela setinha, para deixar claro aqui o do e-mail também, falando o quê? Ele fala, assim: “Olha, eu terminei aqui a minha parte, o que que é a minha parte? Eu enviei e-mail enviado”.
[16:22] E aí, quem está escutando “e-mail enviado”? O log, está escutando “e-mail enviado” e o Analytics está escutando “e-mail enviado”, reparou? O que mais? E quando a fraude deu sucesso? Não tem fraude, o que que a gente vai querer fazer nesse instante?
[16:40] Nesse instante, a gente vai querer validar o pagamento, que eu não sei, deve estar escondido aqui atrás em algum lugar. Então, eu vou copiar para cá e vou colocar: “Efetua o pagamento”. Efetua o pagamento, tem que fazer o quê? Tem que escutar o tópico de “Compra sem fraude”, certo?
[16:56] Então é: “Compra sem fraude”, por exemplo, tá? Você poderia falar outra coisa, outro tópico, você define o tópico, etc., eu estou usando esse exemplo aqui agora, “Compra sem fraude”, opa, desculpa. Então, o fraude envia essa mensagem, o fraude vai enviar a mensagem e qual mensagem que ele envia mesmo?
[17:24] Ele envia a mensagem: “Compra sem fraude”. Quem está escutando esse tópico? O efetua pagamento, o log e o Analytics. Então, repara aqui o que está acontecendo, da maneira que eu estou desenhando os meus sistemas, eu estou falando assim: “Olha, não me importa quem vai escutar o meu status, uma atualização de status, uma situação que ocorreu no meu sistema; ocorreu uma nova compra, um pedido de nova compra; ocorreu um e-mail enviado; ocorreu que a compra foi validada sem fraude; ocorreu que o pagamento foi efetuado com sucesso; ocorreu que o PDF foi gerado com sucesso” .
[18:17] Essas coisas ocorreram, quem está escutando isso para agir, não me importa e isso é o conceito de mensageria, esse conceito de mensageria, de troca de mensagens aparece em diversos sistemas, diversas implementações. O Kafka tem algumas sacadas aqui, algumas são comuns à mensageria e o Kafka tem algumas sacadas especiais dele.
[18:39] Então, uma das sacadas aqui de mensageria é: eu posso ter quantos servidores e serviços rodando de e-mail eu quiser, como eu disse antes, como funcionava antes com o próprio http, se o sistema de fraude é um sistema que consome muito a CPU e pouca memória, eu posso ter várias máquinas com CPUs potentes rodando isso.
[18:59] Se o sistema de gerar PDF, consome pouca CPU, mas muita memória, eu posso ter algumas máquinas com o CPU mediano e bastante memória para elas. Então, você pode escalar de acordo com o necessário.
[19:14] Além disso... Então quer ser, você tira um pontinho de falha aqui, se eu tivesse só uma máquina rodando de fraude, se caísse, eu me dava mal, se eu tenho 10 máquinas rodando, se uma cai, eu ainda tenho nove e por aí, vai, vou tirando os pontos de falha, condicionando redundância.
[19:30] O broker também, você pode replicar, você não precisa ter um único broker rodando, você poder ter um cluster de brokers. Então, eu tenho um cluster com três brokers, por exemplo ou um cluster com 30 brokers, rodando 30 instâncias do Kafka, estou dando exemplo.
[19:47] Então, o que acontece? Quando você envia uma mensagem, essa mensagem vai parar possivelmente em mais de um broker, por quê? Porque se um broker desligar, o outro broker ainda tem essa mensagem. Então, você começa a ter mais tolerância a falha ainda, por quê?
[20:05] Porque se você manda uma mensagem, qualquer mensagem e a mensagem está armazenada em três máquinas, até ela ser recebida, até ela ser recebida por quem quiser, o que que acontece?
[20:15] Se uma dessas máquinas cair, as outras duas ainda tem essa mensagem, se uma dessas máquinas pegar fogo, as outras duas ainda teme essa mensagem. Então, você ganha mais reliability, você consegue garantir que as coisas vão estar lá, serão recebidas, etc.
[20:33] Mais ainda, você consegue rodar isso em paralelo, como a gente está fazendo, você consegue rodar em paralelo. Você consegue com que esses dados, os dados das mensagens que chegam, sejam distribuídos para várias instâncias do fraudador, do detector de fraude.
[20:49] Então, se eu recebi cinco mensagens de novas compras, eu posso mandar dois para um, dois para o outro, um para o outro, por exemplo, se eu tenho três instâncias de fraudador, de detecção de fraude.
[21:00] Eu posso fazer com que se os... Automaticamente, na verdade, se os sistema de (fraudadores) aqui caírem e voltarem só amanhã, porque deu um pau aqui no meu sistema, só voltou amanhã, não tem problema, as mensagens estão armazenadas aqui e eu consigo executar elas um dia depois.
[21:19] Não tem problema, se caiu, “Falhou”, aquelas minhas 10 máquinas caíram por algum motivo e eu não estou conseguindo levantar, eu consigo armazenar essa mensagem por um tempo que eu configuro, posso configurar um tempo ou quantidade de espaço em disco, que eu quero gravar as mensagens, sem problemas.
[21:36] Eu posso também falar: “Olha, pensa bem, se a compra de um usuário foi fraude, eu não quero executar as outras desse usuário”, poderia ser uma definição do sistema, pode ser.
[21:46] Então, o que que você pode fazer? Você pode no Kafka, por mais que a gente execute em parelho, eu estou falando que eu posso executar tudo em paralelo... Você pode em determinados momentos falar: “Olha, as compras para determinado usuário, na mensagem de gerar PDF, eu quero que gerem em sequência”, por quê?
[22:03] Porque se um usuário comprou mil PDFs, eu não quero que fique gerando os mil PDFs daquele usuário e a galera fique esperando, eu quero ir gerando um PDF para cada um, assim eu consigo... A pessoa não vai ler os mil de uma vez, então todo mundo está lendo alguma coisa, por exemplo.
[22:18] Então, você poderia definir regras do gênero, de que olha: “Apesar de que eu quero paralelizável, quando eu penso em um usuário, eu quero que os daquele usuário execute sequencial”.
[22:30] Por exemplo, o estoque, eu reservar o estoque, eu posso executar em paralelo, mas para um produto específico, provavelmente, eu quero reservar o estoque sequencial, eu quero tirar de lá de dentro o do estoque reservado, o estoque em sequência para o produto cinco.
[22:47] Mas, para o produto cinco e para o produto 15, eu posso executar em duas máquinas, em paralelo, não estou nem aí. Então, eu posso usar o produto como chave para serializar a execução, deixar em sequência.
[22:58] Tudo isso, o Kafka é capaz de fazer, tudo isso a gente vai fazer no cursos de Kafka aqui da Alura.


